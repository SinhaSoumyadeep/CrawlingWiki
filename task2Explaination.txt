************************************ Task 2 Explaination ****************************
To merge the urls, the 3 files generated from Task 1 is read which includes the URL and the depth associated with the URL. The urls is in the format url#depth. Each and every line is read and split in to the url and the depth using # as the key and accordingly included in the dictionary which has key as the depth and the value as the list of urls. Thus, urls from depth 1 from each files will be merged and saved as a list of urls for depth one and so on. The overlapping urls which can be encountered in the 3 files are also handeled by either removing or inserted based on priority. Thus, for example url enountered at level 1 in given priority over the same url which is encountered at some another level in another seed list. Thus removing duplicates from the list. Once the list is formed then the url is written into a file called "meregedFile".